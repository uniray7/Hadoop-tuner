import os
import math
import json
import commands
import tt
Heap1 = "-Xmx"
Heap2 = "M"

def extract_configs():
	config_file = open('config.json','r')
	config_json = json.load(config_file)
	configs = config_json['sample_standard_list']
	return configs

def modify_configs(configs,values):
	cmd = XML_PARSER_DIR+'/revise_conf_v1 '+CONF_DIR+'/conf_new/mapred-site.xml'
	i=0
	for conf in configs:
		if conf["type"]=="heap":
			cmd = cmd+str(configs[i]["name"])+Heap1+str(values[i])+Heap2
		elif conf["type"]=="split":
			cmd = cmd+str(configs[i]["name"])+str(values[i]*(2**20))
		else:
			cmd = cmd+str(configs[i]["name"])+str(values[i])
		i=i+1
	os.system(cmd)


def copy_conf_dir():
	cmd = 'cp -r '+CONF_DIR+'/conf_default '+CONF_DIR+'/conf_new'
	os.system(cmd)

def rm_conf_dir():
	cmd = 'rm -rf '+CONF_DIR+'/conf_new'
	os.system(cmd)

def rm_hdfs_output(output_dir):
	cmd = 'hadoop fs -rmr '+output_path
	os.system(cmd)


def get_hdfs_log(output_dir,serial_num):
	cmd = 'hadoop fs -get '+output_dir+'/_logs '+LOG_DIR+'/logs_'+serial_num
	os.system(cmd)	


def gen_log_serial_num():
	cmd = 'ls '+LOG_DIR+'| wc -l'
	serial_num = commands.getoutput(cmd)
	return serial_num

def get_inputdata_size(input_dir):
	cmd = "hadoop fs -dus "+input_dir
	result = commands.getoutput(cmd)
	result = result.split('\t')
	DataSize = int(result[1])/(2**30)
	return DataSize



def run_job(input_dir, output_dir, config_values):
	
	copy_conf_dir()
	
	modify_configs(configs,config_values)


	cmd = 'hadoop --config '+CONF_DIR+'/conf_new jar '+HADOOP_HOME+'/hadoop-examples* terasort '+input_dir+' '+output_dir
#	os.system(cmd)


	log_serial_num = gen_log_serial_num()
	get_hdfs_log(output_dir,log_serial_num)				

	rm_conf_dir()






#extract tuned configs
configs = extract_configs()

#setup environment and path
PATHs_file = open('environment.json','r')
PATHs = json.load(PATHs_file)

HADOOP_HOME = PATHs["HADOOP_HOME"]
CONF_DIR = PATHs["CONF_DIR"]
XML_PARSER_DIR = PATHs["XML_PARSER_DIR"]
LOG_DIR = PATHs["LOG_DIR"]


#Whether the model of the application is existed or not
#If yes, invoke Optimizer to get recommended config. 
#If not, run the job with random config

#if Is_model_exist == true:
#	optimal_config_paras = Optimizer()
#	run_job(input_dir,output_dir,optimal_config_paras)
#else:
#	random_config_paras = random_gen(configs)
#	run_job(input_dir,output_dir,random_config_paras)

input_dir = '/tera-in'
output_dir = '/tera-out'

ran_file = open('random_file','r')
num=0
for para_str in ran_file:
	data_list = json.loads(para_str)
#	run_job(input_dir,output_dir,data_list)

DataSize = get_inputdata_size(input_dir)

test=tt.tt()
test.printf()
